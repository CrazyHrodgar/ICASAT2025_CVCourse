{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f74bf8b",
   "metadata": {},
   "source": [
    "# Detección de objetos en video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b9a730",
   "metadata": {},
   "source": [
    "Este cuaderno implementa un sistema básico de detección y seguimiento de objetos en vídeo utilizando OpenCV y un tracker basado en distancia euclídea.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Objetivo\n",
    "- Detectar objetos en movimiento dentro de una región de interés (ROI) de un vídeo.  \n",
    "- Asignar a cada objeto un identificador único que persista mientras permanezca en escena.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Componentes principales\n",
    "- **Sustracción de fondo (MOG2)**  \n",
    "  Separa el primer plano (objetos en movimiento) del fondo estático.  \n",
    "- **Detección de contornos**  \n",
    "  Extrae las siluetas de cada objeto a partir de la máscara binaria resultante de la sustracción de fondo y un umbral fijo.  \n",
    "- **Tracker euclidiano**  \n",
    "  Mantiene un diccionario de centros de objetos y asigna IDs nuevos o existentes según la proximidad de sus posiciones frame a frame.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Flujo de trabajo\n",
    "1. **Configuración**  \n",
    "   - Importar librerías.  \n",
    "   - Definir la clase `EuclideanDistTracker`.  \n",
    "   - Abrir el vídeo y crear el sustractor de fondo.  \n",
    "2. **Procesamiento por frame**  \n",
    "   1. Leer el siguiente frame y recortar la ROI.  \n",
    "   2. Aplicar sustracción de fondo y umbralización para obtener la máscara binaria.  \n",
    "   3. Encontrar contornos y filtrar por área mínima.  \n",
    "   4. Pasar los bounding boxes al tracker para obtener IDs.  \n",
    "   5. Dibujar rectángulos y etiquetas sobre los objetos en la ROI.  \n",
    "3. **Visualización**  \n",
    "   - Mostrar en tiempo real la ROI anotada, el frame completo y la máscara.  \n",
    "4. **Limpieza**  \n",
    "   - Cerrar la captura de vídeo y destruir las ventanas de OpenCV.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Extensiones posibles\n",
    "- Ajustar parámetros de sustracción y filtrado para distintos escenarios de iluminación y tamaños de objeto.  \n",
    "- Sustituir la detección por un modelo de detección basado en redes neuronales (YOLO, SSD, etc.) para mejorar la precisión.  \n",
    "- Añadir cálculo de trayectoria o velocidad utilizando los IDs asignados para cada objeto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736fe651",
   "metadata": {},
   "source": [
    "En esta celda se importan las dependencias necesarias:\n",
    "- `cv2` de OpenCV, para procesamiento de vídeo e imágenes.  \n",
    "- `math`, para cálculos de distancia euclídea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1977d0",
   "metadata": {},
   "source": [
    "# Código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56cd8a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importat librerías necesarias\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15429a29",
   "metadata": {},
   "source": [
    "Aquí se define la clase encargada de:\n",
    "- Mantener un diccionario de puntos centrales (`center_points`) de objetos detectados.  \n",
    "- Asignar un ID único a cada nuevo objeto con `id_count`.  \n",
    "- El método `update()` recibe una lista de bounding boxes (`[x, y, w, h]`), calcula el centro de cada uno, asocia cada detección con un ID existente (si la distancia entre centros es menor a 25 px) o crea uno nuevo, y devuelve la lista enriquecida con `[x, y, w, h, id]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3622b0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la clase EuclideanDisTracker para medir la distancia entre los objetos\n",
    "class EuclideanDistTracker:\n",
    "    def __init__(self):\n",
    "        # Almacena los centros de cada objeto detectado\n",
    "        self.center_points = {}\n",
    "        # Contador para asignar IDs únicos\n",
    "        self.id_count = 0\n",
    "\n",
    "    def update(self, objects_rect):\n",
    "        \"\"\"\n",
    "        Recibe una lista de bounding boxes [x, y, w, h] y devuelve\n",
    "        la misma lista con un ID asignado a cada objeto: [x, y, w, h, id].\n",
    "        \"\"\"\n",
    "        objects_bbs_ids = []\n",
    "\n",
    "        # Para cada rectángulo, calcular su centro\n",
    "        for rect in objects_rect:\n",
    "            x, y, w, h = rect\n",
    "            cx = (x + x + w) // 2\n",
    "            cy = (y + y + h) // 2\n",
    "\n",
    "            # Buscar si ya tenemos un objeto cercano (distancia < 25 píxeles)\n",
    "            same_object_detected = False\n",
    "            for object_id, pt in self.center_points.items():\n",
    "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
    "                if dist < 25:\n",
    "                    # Actualizar centro y conservar el mismo ID\n",
    "                    self.center_points[object_id] = (cx, cy)\n",
    "                    objects_bbs_ids.append([x, y, w, h, object_id])\n",
    "                    same_object_detected = True\n",
    "                    break\n",
    "\n",
    "            # Si no se encontró ninguno cercano, es un objeto nuevo\n",
    "            if not same_object_detected:\n",
    "                self.center_points[self.id_count] = (cx, cy)\n",
    "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
    "                self.id_count += 1\n",
    "\n",
    "        # Limpiar IDs que ya no están presentes\n",
    "        new_center_points = {}\n",
    "        for _, _, _, _, object_id in objects_bbs_ids:\n",
    "            new_center_points[object_id] = self.center_points[object_id]\n",
    "        self.center_points = new_center_points.copy()\n",
    "\n",
    "        return objects_bbs_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c3d6c",
   "metadata": {},
   "source": [
    "- Se instancia el tracker (`EuclideanDistTracker`).  \n",
    "- Se abre el vídeo `highway.mp4` con `cv2.VideoCapture`.  \n",
    "- Se crea un sustractor de fondo MOG2 (`createBackgroundSubtractorMOG2`) para extraer el foreground en cada frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6adb44f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2.cv2' has no attribute 'createrBackgroundSubtractorMOG2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-340078f86876>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Utilizaremos un detector de fondo tipo MOG2 para extraer el fondo del video\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mobject_detector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreaterBackgroundSubtractorMOG2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvarThreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'createrBackgroundSubtractorMOG2'"
     ]
    }
   ],
   "source": [
    "# Configuración de captura de video y detector de fondo\n",
    "tracker = EuclideanDistTracker()\n",
    "cap = cv2.VideoCapture(\"highway.mp4\")\n",
    "\n",
    "# Utilizaremos un detector de fondo tipo MOG2 para extraer el fondo del video\n",
    "object_detector = cv2.createrBackgroundSubtractorMOG2(history=100, varThreshold=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd140639",
   "metadata": {},
   "source": [
    "1. **Lectura de cada frame** y comprobación de fin de vídeo.  \n",
    "2. **Definición de la ROI** donde se procesarán las detecciones.  \n",
    "3. **Extracción del foreground**:\n",
    "   - Aplicar el sustractor de fondo.  \n",
    "   - Umbralizar para obtener una máscara binaria.  \n",
    "4. **Detección de contornos** en la máscara y filtrado por área mínima (`area > 100`).  \n",
    "5. **Seguimiento**: pasar las detecciones al tracker, recibir `[x, y, w, h, id]` y dibujar rectángulos y etiquetas con el ID.  \n",
    "6. **Visualización** de la ROI, el frame completo y la máscara.  \n",
    "7. **Salida** del bucle al pulsar ESC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4fb209",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Terminar si no hay más frames\n",
    "\n",
    "    # Recortar región de interés (ROI) donde buscar objetos\n",
    "    roi = frame[340:720, 500:800]\n",
    "\n",
    "    # 1) Detección de objetos con sustracción de fondo\n",
    "    mask = object_detector.apply(roi)\n",
    "    _, mask = cv2.threshold(mask, 254, 255, cv2.THRESH_BINARY)\n",
    "    contours, _ = cv2.findContours(mask,\n",
    "                                   cv2.RETR_TREE,\n",
    "                                   cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    detections = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 100:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            detections.append([x, y, w, h])\n",
    "\n",
    "    # 2) Seguimiento: asignar IDs a cada detección\n",
    "    boxes_ids = tracker.update(detections)\n",
    "    for x, y, w, h, object_id in boxes_ids:\n",
    "        # Dibujar el ID y el rectángulo en la ROI\n",
    "        cv2.putText(roi, str(object_id), (x, y - 15),\n",
    "                    cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 2)\n",
    "        cv2.rectangle(roi, (x, y), (x + w, y + h),\n",
    "                      (0, 255, 0), 3)\n",
    "\n",
    "    # Mostrar resultados\n",
    "    cv2.imshow(\"ROI\", roi)\n",
    "    cv2.imshow(\"Frame Completo\", frame)\n",
    "    cv2.imshow(\"Máscara\", mask)\n",
    "\n",
    "    # Salir con la tecla ESC\n",
    "    if cv2.waitKey(30) == 27:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e0ffc",
   "metadata": {},
   "source": [
    "- Cierra la captura de vídeo con `cap.release()`.  \n",
    "- Destruye todas las ventanas de OpenCV con `cv2.destroyAllWindows()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bfbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar los recursos cuando ya terminemos\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2ceeb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2f4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e4a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
